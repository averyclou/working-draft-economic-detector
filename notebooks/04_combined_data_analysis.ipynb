{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bringing It All Together: Complete Economic Analysis\n",
    "\n",
    "Time to combine everything we've got - FRED economic data, NBER recession dates, and consumer sentiment - into one comprehensive dataset. This is where we'll see the full picture of how different economic signals work together to predict downturns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import notebook utilities\n",
    "from notebook_utils import init_notebook, load_data, display_data_info, save_figure\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "\n",
    "# Initialize notebook environment\n",
    "init_notebook()\n",
    "\n",
    "# Import from econ_downturn package\n",
    "from econ_downturn import (\n",
    "    engineer_features, normalize_data, apply_mda, create_discriminant_time_series,\n",
    "    plot_indicator_with_recessions, plot_correlation_matrix,\n",
    "    plot_feature_importance, plot_discriminant_time_series,\n",
    "    plot_sentiment_vs_indicator, plot_sentiment_correlation_matrix\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading All Our Data Sources\n",
    "\n",
    "Let's pull together data from all our sources - FRED economic indicators, NBER recession dates, and University of Michigan consumer sentiment. This gives us the complete picture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all data using the utility function\n",
    "merged_data = load_data(use_cached=False)  # Force reload from original sources\n",
    "\n",
    "# Display information about the dataset\n",
    "display_data_info(merged_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Consumer Sentiment Patterns\n",
    "\n",
    "Now let's see how consumer sentiment behaves around recessions. Does it drop before economic downturns? How does it relate to other indicators like unemployment and GDP?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot consumer sentiment over time with recession periods\n",
    "fig = plot_indicator_with_recessions(\n",
    "    merged_data, \n",
    "    'SENTIMENT', \n",
    "    title='Consumer Sentiment with Recession Periods'\n",
    ")\n",
    "plt.show()\n",
    "save_figure(fig, \"consumer_sentiment.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot consumer sentiment vs unemployment rate\n",
    "fig = plot_sentiment_vs_indicator(\n",
    "    merged_data,\n",
    "    sentiment_col='SENTIMENT',\n",
    "    indicator_col='UNEMPLOYMENT'\n",
    ")\n",
    "plt.show()\n",
    "save_figure(fig, \"sentiment_vs_unemployment.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot consumer sentiment vs GDP growth\n",
    "fig = plot_sentiment_vs_indicator(\n",
    "    merged_data,\n",
    "    sentiment_col='SENTIMENT',\n",
    "    indicator_col='GDP'\n",
    ")\n",
    "plt.show()\n",
    "save_figure(fig, \"sentiment_vs_gdp.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot correlations between consumer sentiment and economic indicators\n",
    "fig = plot_sentiment_correlation_matrix(\n",
    "    merged_data,\n",
    "    sentiment_cols=['SENTIMENT'],\n",
    "    top_n=10\n",
    ")\n",
    "plt.show()\n",
    "save_figure(fig, \"sentiment_correlation_matrix.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Engineering Features with Sentiment Data\n",
    "\n",
    "Time to create some smart features using our combined dataset. We'll build lag variables and transformations that capture how sentiment and economic indicators interact over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values and create lag variables\n",
    "data_with_features = engineer_features(merged_data)\n",
    "\n",
    "print(f\"Data with features shape: {data_with_features.shape}\")\n",
    "print(f\"Number of features: {data_with_features.shape[1]}\")\n",
    "\n",
    "# Save the dataset with features\n",
    "from econ_downturn import get_data_paths\n",
    "data_paths = get_data_paths()\n",
    "output_dir = data_paths['processed_dir']\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "features_path = os.path.join(output_dir, 'data_with_features_and_sentiment.csv')\n",
    "data_with_features.to_csv(features_path)\n",
    "print(f\"Saved dataset with features to {features_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing for Fair Comparison\n",
    "\n",
    "Different indicators have different scales, so let's normalize everything to ensure our model treats all features equally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "data_normalized, scaler = normalize_data(data_with_features)\n",
    "\n",
    "print(f\"Normalized data shape: {data_normalized.shape}\")\n",
    "\n",
    "# Save the normalized dataset\n",
    "normalized_path = os.path.join(output_dir, 'data_normalized_with_sentiment.csv')\n",
    "data_normalized.to_csv(normalized_path)\n",
    "print(f\"Saved normalized dataset to {normalized_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Our Enhanced Model\n",
    "\n",
    "The moment of truth - does adding consumer sentiment actually make our recession prediction model better? Let's run a quick test and see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = data_normalized.drop(columns=['recession'])\n",
    "y = data_normalized['recession']\n",
    "\n",
    "# Apply MDA\n",
    "mda_results = apply_mda(X, y)\n",
    "\n",
    "# Print model performance metrics\n",
    "print(f\"Accuracy: {mda_results['accuracy']:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(mda_results['conf_matrix'])\n",
    "print(\"\\nClassification Report:\")\n",
    "print(mda_results['class_report'])\n",
    "print(f\"\\nCross-Validation Scores: {mda_results['cv_scores']}\")\n",
    "print(f\"Mean CV Score: {mda_results['cv_scores'].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature importances\n",
    "if mda_results['feature_importance'] is not None:\n",
    "    fig = plot_feature_importance(mda_results['feature_importance'])\n",
    "    plt.show()\n",
    "    save_figure(fig, \"feature_importance_with_sentiment.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and plot discriminant time series\n",
    "discriminant_df = create_discriminant_time_series(\n",
    "    mda_results['model'], X, y\n",
    ")\n",
    "\n",
    "fig = plot_discriminant_time_series(discriminant_df)\n",
    "plt.show()\n",
    "save_figure(fig, \"discriminant_time_series_with_sentiment.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "econ-downturn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
