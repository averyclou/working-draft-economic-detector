{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection for Economic Downturn Detection\n",
    "\n",
    "This notebook handles the collection of all economic data sources needed for the recession prediction model. It pulls data from multiple sources and combines them into a unified dataset for analysis.\n",
    "\n",
    "## Data Sources\n",
    "\n",
    "1. **Federal Reserve Economic Data (FRED)**: Core economic indicators like GDP, unemployment, inflation, consumer sentiment\n",
    "2. **National Bureau of Economic Research (NBER)**: Official recession dates and periods\n",
    "3. **University of Michigan**: Additional consumer sentiment surveys and expectations\n",
    "\n",
    "## Data Coverage\n",
    "\n",
    "**Data Cutoff Date**: May 2024\n",
    "\n",
    "We collect data from January 1970 through May 2024, covering 8 recession periods and multiple economic cycles. This gives us enough historical data for model training while including recent economic conditions.\n",
    "\n",
    "## Requirements\n",
    "\n",
    "- FRED API key (set in .env file as FRED_API_KEY)\n",
    "- Internet connection for data fetching\n",
    "- Sufficient disk space for data storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize notebook with all necessary imports and setup\n",
    "from notebook_utils import init_notebook\n",
    "init_notebook()\n",
    "\n",
    "# Import required libraries\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import logging\n",
    "from dotenv import load_dotenv\n",
    "from fredapi import Fred\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import the econ_downturn functions we need\n",
    "from econ_downturn import (\n",
    "    get_fred_data, get_nber_data, get_all_data, get_umich_data,\n",
    "    setup_logger, load_environment\n",
    ")\n",
    "\n",
    "# Set up logging\n",
    "logger = setup_logger('data_collection')\n",
    "\n",
    "print(\"Data collection notebook initialized successfully!\")\n",
    "print(f\"Current working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. FRED API Setup and Validation\n",
    "\n",
    "Let's check that the FRED API key is set up correctly and test the connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check FRED API key\n",
    "fred_api_key = os.getenv('FRED_API_KEY')\n",
    "\n",
    "if not fred_api_key:\n",
    "    print(\"FRED API key not found!\")\n",
    "    print(\"Please set the FRED_API_KEY environment variable in your .env file.\")\n",
    "    print(\"You can get a free API key from: https://fred.stlouisfed.org/\")\n",
    "    sys.exit(1)\n",
    "else:\n",
    "    print(\"FRED API key found\")\n",
    "    \n",
    "# Test FRED API connection\n",
    "try:\n",
    "    fred = Fred(api_key=fred_api_key)\n",
    "    # Test with a simple series\n",
    "    test_data = fred.get_series('UNRATE', limit=1)\n",
    "    print(\"FRED API connection successful\")\n",
    "    print(f\"Latest unemployment rate: {test_data.iloc[-1]:.1f}% ({test_data.index[-1].strftime('%Y-%m')})\")\n",
    "except Exception as e:\n",
    "    print(f\"FRED API connection failed: {e}\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Data Collection Parameters\n",
    "\n",
    "Set the date range and output directories for data collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data collection parameters\n",
    "START_DATE = '1970-01-01'\n",
    "END_DATE = '2024-05-31'  # Data cutoff date\n",
    "\n",
    "# Create output directories\n",
    "DATA_DIR = '../data'\n",
    "FRED_DIR = os.path.join(DATA_DIR, 'fred')\n",
    "NBER_DIR = os.path.join(DATA_DIR, 'nber')\n",
    "UMICH_DIR = os.path.join(DATA_DIR, 'umich')\n",
    "PROCESSED_DIR = os.path.join(DATA_DIR, 'processed')\n",
    "\n",
    "# Create directories if they don't exist\n",
    "for directory in [FRED_DIR, NBER_DIR, UMICH_DIR, PROCESSED_DIR]:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    \n",
    "print(f\"Data collection period: {START_DATE} to {END_DATE}\")\n",
    "print(f\"Output directories created in: {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fetch FRED Economic Indicators\n",
    "\n",
    "Get the main economic indicators from the Federal Reserve Economic Data (FRED) database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Fetching FRED economic indicators...\")\n",
    "print(\"This may take a few minutes depending on your internet connection.\")\n",
    "\n",
    "# Fetch FRED data using the existing function\n",
    "fred_data = get_fred_data(\n",
    "    api_key=fred_api_key,\n",
    "    start_date=START_DATE,\n",
    "    end_date=END_DATE,\n",
    "    output_dir=FRED_DIR\n",
    ")\n",
    "\n",
    "if fred_data is not None:\n",
    "    print(f\"FRED data collected successfully!\")\n",
    "    print(f\"   Shape: {fred_data.shape}\")\n",
    "    print(f\"   Date range: {fred_data.index.min()} to {fred_data.index.max()}\")\n",
    "    print(f\"   Indicators: {list(fred_data.columns)}\")\n",
    "else:\n",
    "    print(\"Failed to fetch FRED data\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fetch NBER Recession Data\n",
    "\n",
    "Get official recession dates from the National Bureau of Economic Research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Fetching NBER recession data...\")\n",
    "\n",
    "# Fetch NBER data using the existing function\n",
    "nber_data = get_nber_data(\n",
    "    start_date=START_DATE,\n",
    "    end_date=END_DATE,\n",
    "    output_dir=NBER_DIR\n",
    ")\n",
    "\n",
    "if nber_data is not None:\n",
    "    print(f\"NBER recession data collected successfully!\")\n",
    "    print(f\"   Shape: {nber_data.shape}\")\n",
    "    print(f\"   Date range: {nber_data.index.min()} to {nber_data.index.max()}\")\n",
    "    print(f\"   Recession periods: {nber_data['recession'].sum()} months\")\n",
    "    print(f\"   Non-recession periods: {(nber_data['recession'] == 0).sum()} months\")\n",
    "else:\n",
    "    print(\"Failed to fetch NBER data\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Fetch University of Michigan Consumer Sentiment Data\n",
    "\n",
    "Get additional consumer sentiment data from the University of Michigan via FRED."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Fetching University of Michigan Consumer Sentiment data...\")\n",
    "\n",
    "# Use the existing get_umich_data function\n",
    "from econ_downturn import get_umich_data\n",
    "\n",
    "umich_data = get_umich_data(\n",
    "    api_key=fred_api_key,\n",
    "    start_date=START_DATE,\n",
    "    end_date=END_DATE,\n",
    "    output_dir=UMICH_DIR\n",
    ")\n",
    "\n",
    "if umich_data is not None:\n",
    "    print(f\"UMich sentiment data collected successfully!\")\n",
    "    print(f\"   Shape: {umich_data.shape}\")\n",
    "    print(f\"   Date range: {umich_data.index.min()} to {umich_data.index.max()}\")\n",
    "    print(f\"   Indicators: {list(umich_data.columns)}\")\n",
    "else:\n",
    "    print(\"Failed to fetch UMich data\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Integrate All Data Sources\n",
    "\n",
    "Combine all the data sources we've collected into one dataset for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Integrating all data sources...\")\n",
    "\n",
    "# Use the existing get_all_data function to integrate FRED, NBER, and UMich data\n",
    "try:\n",
    "    integrated_data = get_all_data()\n",
    "    print(f\"Integrated data loaded successfully: {integrated_data.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"get_all_data() failed: {e}\")\n",
    "    print(\"Manually combining data sources...\")\n",
    "    \n",
    "    # Manually combine the data if get_all_data fails\n",
    "    data_sources = []\n",
    "    \n",
    "    if fred_data is not None:\n",
    "        data_sources.append(fred_data)\n",
    "        print(f\"   Added FRED data: {fred_data.shape}\")\n",
    "    if nber_data is not None:\n",
    "        data_sources.append(nber_data)\n",
    "        print(f\"   Added NBER data: {nber_data.shape}\")\n",
    "    if umich_data is not None:\n",
    "        data_sources.append(umich_data)\n",
    "        print(f\"   Added UMich data: {umich_data.shape}\")\n",
    "    \n",
    "    if data_sources:\n",
    "        integrated_data = pd.concat(data_sources, axis=1)\n",
    "        print(f\"   Manually integrated data: {integrated_data.shape}\")\n",
    "    else:\n",
    "        print(\"No data sources available for integration\")\n",
    "        sys.exit(1)\n",
    "\n",
    "# Handle missing values with forward fill then backward fill\n",
    "integrated_data = integrated_data.fillna(method='ffill').fillna(method='bfill')\n",
    "\n",
    "# Save the integrated dataset\n",
    "integrated_path = os.path.join(PROCESSED_DIR, 'integrated_data.csv')\n",
    "integrated_data.to_csv(integrated_path)\n",
    "\n",
    "print(f\"\\nFinal integrated dataset:\")\n",
    "print(f\"   Shape: {integrated_data.shape}\")\n",
    "print(f\"   Date range: {integrated_data.index.min()} to {integrated_data.index.max()}\")\n",
    "print(f\"   Saved to: {integrated_path}\")\n",
    "print(f\"   Columns: {list(integrated_data.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Data Collection Summary\n",
    "\n",
    "Summary of all the data we've collected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DATA COLLECTION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nCollection Period: {START_DATE} to {END_DATE}\")\n",
    "print(f\"Total Data Points: {len(integrated_data)} time periods\")\n",
    "print(f\"Total Indicators: {len(integrated_data.columns)} variables\")\n",
    "\n",
    "print(\"\\nData Sources Collected:\")\n",
    "\n",
    "# FRED data summary\n",
    "if fred_data is not None:\n",
    "    print(f\"   FRED Economic Indicators: {fred_data.shape[1]} indicators\")\n",
    "    print(f\"      - GDP, Unemployment, CPI, Fed Funds Rate, etc.\")\n",
    "else:\n",
    "    print(f\"   FRED Economic Indicators: Failed\")\n",
    "\n",
    "# NBER data summary\n",
    "if nber_data is not None:\n",
    "    recession_months = nber_data['recession'].sum()\n",
    "    total_months = len(nber_data)\n",
    "    recession_pct = (recession_months / total_months) * 100\n",
    "    print(f\"   NBER Recession Data: {recession_months}/{total_months} recession months ({recession_pct:.1f}%)\")\n",
    "else:\n",
    "    print(f\"   NBER Recession Data: Failed\")\n",
    "\n",
    "# UMich data summary\n",
    "if umich_data is not None:\n",
    "    print(f\"   UMich Consumer Sentiment: {umich_data.shape[1]} indicators\")\n",
    "    print(f\"      - Consumer Sentiment, Current Conditions, Expectations, Inflation Expectations\")\n",
    "else:\n",
    "    print(f\"   UMich Consumer Sentiment: Failed\")\n",
    "\n",
    "print(f\"\\nData Storage:\")\n",
    "print(f\"   Raw data saved in: {DATA_DIR}/[source]/\")\n",
    "print(f\"   Integrated data saved in: {integrated_path}\")\n",
    "\n",
    "print(f\"\\nData collection completed successfully!\")\n",
    "print(f\"   The integrated dataset is ready for feature engineering and analysis.\")\n",
    "print(f\"   Next step: Run notebook 01_data_exploration.ipynb\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "econ-downturn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
