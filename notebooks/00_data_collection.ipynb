{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection for Economic Downturn Detection\n",
    "\n",
    "This notebook handles the collection of all economic data sources needed for the recession prediction model. It pulls data from multiple sources and combines them into a unified dataset for analysis.\n",
    "\n",
    "## Data Sources\n",
    "\n",
    "1. **Federal Reserve Economic Data (FRED)**: Core economic indicators like GDP, unemployment, inflation\n",
    "2. **National Bureau of Economic Research (NBER)**: Official recession dates and periods\n",
    "3. **University of Michigan**: Consumer sentiment surveys and expectations\n",
    "4. **Conference Board**: Consumer confidence index\n",
    "5. **Business Sentiment Indicators**: Manufacturing PMI, business optimism, CEO confidence\n",
    "\n",
    "## Data Coverage\n",
    "\n",
    "**Data Cutoff Date**: May 2024\n",
    "\n",
    "We collect data from January 1970 through May 2024, covering 8 recession periods and multiple economic cycles. This gives us enough historical data for model training while including recent economic conditions.\n",
    "\n",
    "## Requirements\n",
    "\n",
    "- FRED API key (set in .env file as FRED_API_KEY)\n",
    "- Internet connection for data fetching\n",
    "- Sufficient disk space for data storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import logging\n",
    "from dotenv import load_dotenv\n",
    "from fredapi import Fred\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add the src directory to the path\n",
    "sys.path.append('../src')\n",
    "\n",
    "# Import the econ_downturn package\n",
    "from econ_downturn import (\n",
    "    get_fred_data, get_nber_data, get_all_data,\n",
    "    setup_logger, load_environment\n",
    ")\n",
    "\n",
    "# Set up logging\n",
    "logger = setup_logger('data_collection')\n",
    "\n",
    "# Load environment variables\n",
    "load_environment()\n",
    "\n",
    "print(\"Data collection notebook initialized successfully!\")\n",
    "print(f\"Current working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. FRED API Setup and Validation\n",
    "\n",
    "Let's check that the FRED API key is set up correctly and test the connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check FRED API key\n",
    "fred_api_key = os.getenv('FRED_API_KEY')\n",
    "\n",
    "if not fred_api_key:\n",
    "    print(\"FRED API key not found!\")\n",
    "    print(\"Please set the FRED_API_KEY environment variable in your .env file.\")\n",
    "    print(\"You can get a free API key from: https://fred.stlouisfed.org/\")\n",
    "    sys.exit(1)\n",
    "else:\n",
    "    print(\"FRED API key found\")\n",
    "    \n",
    "# Test FRED API connection\n",
    "try:\n",
    "    fred = Fred(api_key=fred_api_key)\n",
    "    # Test with a simple series\n",
    "    test_data = fred.get_series('UNRATE', limit=1)\n",
    "    print(\"FRED API connection successful\")\n",
    "    print(f\"Latest unemployment rate: {test_data.iloc[-1]:.1f}% ({test_data.index[-1].strftime('%Y-%m')})\")\n",
    "except Exception as e:\n",
    "    print(f\"FRED API connection failed: {e}\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Data Collection Parameters\n",
    "\n",
    "Set the date range and output directories for data collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data collection parameters\n",
    "START_DATE = '1970-01-01'\n",
    "END_DATE = '2024-05-31'  # Data cutoff date\n",
    "\n",
    "# Create output directories\n",
    "DATA_DIR = '../data'\n",
    "FRED_DIR = os.path.join(DATA_DIR, 'fred')\n",
    "NBER_DIR = os.path.join(DATA_DIR, 'nber')\n",
    "UMICH_DIR = os.path.join(DATA_DIR, 'umich')\n",
    "CONF_BOARD_DIR = os.path.join(DATA_DIR, 'conf_board')\n",
    "BUSINESS_DIR = os.path.join(DATA_DIR, 'business')\n",
    "PROCESSED_DIR = os.path.join(DATA_DIR, 'processed')\n",
    "\n",
    "# Create directories if they don't exist\n",
    "for directory in [FRED_DIR, NBER_DIR, UMICH_DIR, CONF_BOARD_DIR, BUSINESS_DIR, PROCESSED_DIR]:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    \n",
    "print(f\"Data collection period: {START_DATE} to {END_DATE}\")\n",
    "print(f\"Output directories created in: {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fetch FRED Economic Indicators\n",
    "\n",
    "Get the main economic indicators from the Federal Reserve Economic Data (FRED) database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Fetching FRED economic indicators...\")\n",
    "print(\"This may take a few minutes depending on your internet connection.\")\n",
    "\n",
    "# Fetch FRED data using the existing function\n",
    "fred_data = get_fred_data(\n",
    "    api_key=fred_api_key,\n",
    "    start_date=START_DATE,\n",
    "    end_date=END_DATE,\n",
    "    output_dir=FRED_DIR\n",
    ")\n",
    "\n",
    "if fred_data is not None:\n",
    "    print(f\"FRED data collected successfully!\")\n",
    "    print(f\"   Shape: {fred_data.shape}\")\n",
    "    print(f\"   Date range: {fred_data.index.min()} to {fred_data.index.max()}\")\n",
    "    print(f\"   Indicators: {list(fred_data.columns)}\")\n",
    "else:\n",
    "    print(\"Failed to fetch FRED data\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fetch NBER Recession Data\n",
    "\n",
    "Get official recession dates from the National Bureau of Economic Research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Fetching NBER recession data...\")\n",
    "\n",
    "# Fetch NBER data using the existing function\n",
    "nber_data = get_nber_data(\n",
    "    start_date=START_DATE,\n",
    "    end_date=END_DATE,\n",
    "    output_dir=NBER_DIR\n",
    ")\n",
    "\n",
    "if nber_data is not None:\n",
    "    print(f\"NBER recession data collected successfully!\")\n",
    "    print(f\"   Shape: {nber_data.shape}\")\n",
    "    print(f\"   Date range: {nber_data.index.min()} to {nber_data.index.max()}\")\n",
    "    print(f\"   Recession periods: {nber_data['recession'].sum()} months\")\n",
    "    print(f\"   Non-recession periods: {(nber_data['recession'] == 0).sum()} months\")\n",
    "else:\n",
    "    print(\"Failed to fetch NBER data\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Fetch University of Michigan Consumer Sentiment Data\n",
    "\n",
    "Get consumer sentiment data from the University of Michigan via FRED."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_umich_data(api_key, start_date='1970-01-01', end_date=None, output_dir='../data/umich'):\n",
    "    \"\"\"\n",
    "    Fetch University of Michigan Consumer Sentiment data from FRED.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    api_key : str\n",
    "        FRED API key\n",
    "    start_date : str\n",
    "        Start date in 'YYYY-MM-DD' format\n",
    "    end_date : str\n",
    "        End date in 'YYYY-MM-DD' format, defaults to current date\n",
    "    output_dir : str\n",
    "        Directory to save the CSV files\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        Merged dataset with all UMich sentiment indicators\n",
    "    \"\"\"\n",
    "    if end_date is None:\n",
    "        end_date = datetime.now().strftime('%Y-%m-%d')\n",
    "    \n",
    "    # UMich sentiment indicators from FRED\n",
    "    umich_indicators = {\n",
    "        'SENTIMENT': 'UMCSENT',     # University of Michigan: Consumer Sentiment\n",
    "        'CURRENT': 'UMCURRENT',     # University of Michigan: Current Economic Conditions\n",
    "        'EXPECTED': 'UMEXPECT',     # University of Michigan: Consumer Expectations\n",
    "        'INFLATION_1Y': 'MICH1YR',  # University of Michigan: Inflation Expectation (1-Year)\n",
    "        'INFLATION_5Y': 'MICH5YR'   # University of Michigan: Inflation Expectation (5-Year)\n",
    "    }\n",
    "    \n",
    "    fred = Fred(api_key=api_key)\n",
    "    data_frames = []\n",
    "    \n",
    "    for name, series_id in umich_indicators.items():\n",
    "        try:\n",
    "            logger.info(f\"Fetching {name} (Series ID: {series_id})\")\n",
    "            series = fred.get_series(series_id, start_date, end_date)\n",
    "            df = pd.DataFrame({name: series})\n",
    "            data_frames.append(df)\n",
    "            logger.info(f\"Successfully fetched {name} with {len(series)} observations\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error fetching {name}: {e}\")\n",
    "    \n",
    "    if data_frames:\n",
    "        # Merge all DataFrames\n",
    "        merged_data = pd.concat(data_frames, axis=1)\n",
    "        \n",
    "        # Create output directory\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # Save individual series\n",
    "        for name, df in zip(umich_indicators.keys(), data_frames):\n",
    "            output_path = os.path.join(output_dir, f\"{name.lower()}.csv\")\n",
    "            df.to_csv(output_path)\n",
    "            logger.info(f\"Saved {name} to {output_path}\")\n",
    "        \n",
    "        # Save merged data\n",
    "        merged_path = os.path.join(output_dir, \"all_sentiment.csv\")\n",
    "        merged_data.to_csv(merged_path)\n",
    "        logger.info(f\"Saved merged UMich data to {merged_path}\")\n",
    "        \n",
    "        return merged_data\n",
    "    else:\n",
    "        logger.error(\"No UMich data was successfully fetched\")\n",
    "        return None\n",
    "\n",
    "print(\"Fetching University of Michigan Consumer Sentiment data...\")\n",
    "\n",
    "umich_data = fetch_umich_data(\n",
    "    api_key=fred_api_key,\n",
    "    start_date=START_DATE,\n",
    "    end_date=END_DATE,\n",
    "    output_dir=UMICH_DIR\n",
    ")\n",
    "\n",
    "if umich_data is not None:\n",
    "    print(f\"UMich sentiment data collected successfully!\")\n",
    "    print(f\"   Shape: {umich_data.shape}\")\n",
    "    print(f\"   Date range: {umich_data.index.min()} to {umich_data.index.max()}\")\n",
    "    print(f\"   Indicators: {list(umich_data.columns)}\")\n",
    "else:\n",
    "    print(\"Failed to fetch UMich data\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Fetch Conference Board Consumer Confidence Index\n",
    "\n",
    "Get the Conference Board Consumer Confidence Index from FRED."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_conference_board_data(api_key, start_date='1970-01-01', end_date=None, output_dir='../data/conf_board'):\n",
    "    \"\"\"\n",
    "    Fetch Conference Board Consumer Confidence Index data from FRED.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    api_key : str\n",
    "        FRED API key\n",
    "    start_date : str\n",
    "        Start date in 'YYYY-MM-DD' format\n",
    "    end_date : str\n",
    "        End date in 'YYYY-MM-DD' format, defaults to current date\n",
    "    output_dir : str\n",
    "        Directory to save the CSV files\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        DataFrame with Conference Board Consumer Confidence Index\n",
    "    \"\"\"\n",
    "    if end_date is None:\n",
    "        end_date = datetime.now().strftime('%Y-%m-%d')\n",
    "    \n",
    "    # FRED series ID for Conference Board Consumer Confidence Index\n",
    "    series_id = 'CSCICP03USM665S'\n",
    "    \n",
    "    try:\n",
    "        fred = Fred(api_key=api_key)\n",
    "        logger.info(f\"Fetching Conference Board Consumer Confidence Index (Series ID: {series_id})\")\n",
    "        \n",
    "        # Fetch data from FRED\n",
    "        data = fred.get_series(series_id, start_date, end_date)\n",
    "        \n",
    "        # Convert to DataFrame\n",
    "        df = pd.DataFrame(data, columns=['CONF_BOARD'])\n",
    "        df.index.name = 'date'\n",
    "        \n",
    "        logger.info(f\"Fetched Conference Board data with shape: {df.shape}\")\n",
    "        \n",
    "        # Create output directory and save to CSV\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        output_path = os.path.join(output_dir, 'consumer_confidence.csv')\n",
    "        df.to_csv(output_path)\n",
    "        logger.info(f\"Saved Conference Board data to {output_path}\")\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error fetching Conference Board data: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "print(\"Fetching Conference Board Consumer Confidence Index...\")\n",
    "\n",
    "conf_board_data = fetch_conference_board_data(\n",
    "    api_key=fred_api_key,\n",
    "    start_date=START_DATE,\n",
    "    end_date=END_DATE,\n",
    "    output_dir=CONF_BOARD_DIR\n",
    ")\n",
    "\n",
    "if not conf_board_data.empty:\n",
    "    print(f\"Conference Board data collected successfully!\")\n",
    "    print(f\"   Shape: {conf_board_data.shape}\")\n",
    "    print(f\"   Date range: {conf_board_data.index.min()} to {conf_board_data.index.max()}\")\n",
    "else:\n",
    "    print(\"Conference Board data collection failed, but continuing...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Fetch Business Sentiment Indicators\n",
    "\n",
    "Get various business sentiment indicators from FRED."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_business_sentiment_data(api_key, start_date='1970-01-01', end_date=None, output_dir='../data/business'):\n",
    "    \"\"\"\n",
    "    Fetch business sentiment indicators from FRED.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    api_key : str\n",
    "        FRED API key\n",
    "    start_date : str\n",
    "        Start date in 'YYYY-MM-DD' format\n",
    "    end_date : str\n",
    "        End date in 'YYYY-MM-DD' format, defaults to current date\n",
    "    output_dir : str\n",
    "        Directory to save the CSV files\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        DataFrame with business sentiment indicators\n",
    "    \"\"\"\n",
    "    if end_date is None:\n",
    "        end_date = datetime.now().strftime('%Y-%m-%d')\n",
    "    \n",
    "    # FRED series IDs for business sentiment indicators\n",
    "    series_ids = {\n",
    "        'ISM_PMI': 'MANEMP',           # ISM Manufacturing PMI\n",
    "        'ISM_NONMFG': 'NMFBAI',        # ISM Non-Manufacturing Index\n",
    "        'BUS_OPTIMISM': 'NFCIBUSOPX',  # NFIB Small Business Optimism Index\n",
    "        'CEO_CONFIDENCE': 'CEOCONF',   # CEO Confidence Index\n",
    "        'PHILLY_FED': 'USPHCI'         # Philadelphia Fed Business Outlook Survey\n",
    "    }\n",
    "    \n",
    "    fred = Fred(api_key=api_key)\n",
    "    data_frames = []\n",
    "    \n",
    "    for name, series_id in series_ids.items():\n",
    "        try:\n",
    "            logger.info(f\"Fetching {name} (Series ID: {series_id})\")\n",
    "            # Fetch data from FRED\n",
    "            data = fred.get_series(series_id, start_date, end_date)\n",
    "            \n",
    "            # Convert to DataFrame\n",
    "            df = pd.DataFrame(data, columns=[name])\n",
    "            df.index.name = 'date'\n",
    "            \n",
    "            data_frames.append(df)\n",
    "            logger.info(f\"Fetched {name} data with shape: {df.shape}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Could not fetch {name}: {e}\")\n",
    "    \n",
    "    if data_frames:\n",
    "        # Merge all DataFrames\n",
    "        merged_df = pd.concat(data_frames, axis=1)\n",
    "        \n",
    "        logger.info(f\"Merged business sentiment data with shape: {merged_df.shape}\")\n",
    "        \n",
    "        # Create output directory and save to CSV\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        output_path = os.path.join(output_dir, 'business_sentiment.csv')\n",
    "        merged_df.to_csv(output_path)\n",
    "        logger.info(f\"Saved business sentiment data to {output_path}\")\n",
    "        \n",
    "        return merged_df\n",
    "    else:\n",
    "        logger.warning(\"No business sentiment data fetched\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "print(\"Fetching business sentiment indicators...\")\n",
    "\n",
    "business_data = fetch_business_sentiment_data(\n",
    "    api_key=fred_api_key,\n",
    "    start_date=START_DATE,\n",
    "    end_date=END_DATE,\n",
    "    output_dir=BUSINESS_DIR\n",
    ")\n",
    "\n",
    "if not business_data.empty:\n",
    "    print(f\"Business sentiment data collected successfully!\")\n",
    "    print(f\"   Shape: {business_data.shape}\")\n",
    "    print(f\"   Date range: {business_data.index.min()} to {business_data.index.max()}\")\n",
    "    print(f\"   Indicators: {list(business_data.columns)}\")\n",
    "else:\n",
    "    print(\"Business sentiment data collection failed, but continuing...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Integrate All Data Sources\n",
    "\n",
    "Combine all the data sources we've collected into one dataset for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Integrating all data sources...\")\n",
    "\n",
    "# Start with the core data from get_all_data function\n",
    "try:\n",
    "    integrated_data = get_all_data()\n",
    "    print(f\"Core data loaded: {integrated_data.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to load core data: {e}\")\n",
    "    # If get_all_data fails, manually combine the data\n",
    "    data_sources = []\n",
    "    \n",
    "    if fred_data is not None:\n",
    "        data_sources.append(fred_data)\n",
    "    if nber_data is not None:\n",
    "        data_sources.append(nber_data)\n",
    "    if umich_data is not None:\n",
    "        data_sources.append(umich_data)\n",
    "    \n",
    "    if data_sources:\n",
    "        integrated_data = pd.concat(data_sources, axis=1)\n",
    "        print(f\"Manually integrated core data: {integrated_data.shape}\")\n",
    "    else:\n",
    "        print(\"No data sources available for integration\")\n",
    "        sys.exit(1)\n",
    "\n",
    "# Add Conference Board data if available\n",
    "if not conf_board_data.empty:\n",
    "    integrated_data = pd.concat([integrated_data, conf_board_data], axis=1)\n",
    "    print(f\"Added Conference Board data: {integrated_data.shape}\")\n",
    "\n",
    "# Add business sentiment data if available\n",
    "if not business_data.empty:\n",
    "    integrated_data = pd.concat([integrated_data, business_data], axis=1)\n",
    "    print(f\"Added business sentiment data: {integrated_data.shape}\")\n",
    "\n",
    "# Handle missing values with forward fill then backward fill\n",
    "integrated_data = integrated_data.fillna(method='ffill').fillna(method='bfill')\n",
    "\n",
    "# Save the integrated dataset\n",
    "integrated_path = os.path.join(PROCESSED_DIR, 'integrated_data.csv')\n",
    "integrated_data.to_csv(integrated_path)\n",
    "\n",
    "print(f\"\\nFinal integrated dataset:\")\n",
    "print(f\"   Shape: {integrated_data.shape}\")\n",
    "print(f\"   Date range: {integrated_data.index.min()} to {integrated_data.index.max()}\")\n",
    "print(f\"   Saved to: {integrated_path}\")\n",
    "print(f\"   Columns: {list(integrated_data.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Data Collection Summary\n",
    "\n",
    "Summary of all the data we've collected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DATA COLLECTION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nCollection Period: {START_DATE} to {END_DATE}\")\n",
    "print(f\"Total Data Points: {len(integrated_data)} time periods\")\n",
    "print(f\"Total Indicators: {len(integrated_data.columns)} variables\")\n",
    "\n",
    "print(\"\\nData Sources Collected:\")\n",
    "\n",
    "# FRED data summary\n",
    "if fred_data is not None:\n",
    "    print(f\"   FRED Economic Indicators: {fred_data.shape[1]} indicators\")\n",
    "    print(f\"      - GDP, Unemployment, CPI, Fed Funds Rate, etc.\")\n",
    "else:\n",
    "    print(f\"   FRED Economic Indicators: Failed\")\n",
    "\n",
    "# NBER data summary\n",
    "if nber_data is not None:\n",
    "    recession_months = nber_data['recession'].sum()\n",
    "    total_months = len(nber_data)\n",
    "    recession_pct = (recession_months / total_months) * 100\n",
    "    print(f\"   NBER Recession Data: {recession_months}/{total_months} recession months ({recession_pct:.1f}%)\")\n",
    "else:\n",
    "    print(f\"   NBER Recession Data: Failed\")\n",
    "\n",
    "# UMich data summary\n",
    "if umich_data is not None:\n",
    "    print(f\"   UMich Consumer Sentiment: {umich_data.shape[1]} indicators\")\n",
    "    print(f\"      - Consumer Sentiment, Current Conditions, Expectations, etc.\")\n",
    "else:\n",
    "    print(f\"   UMich Consumer Sentiment: Failed\")\n",
    "\n",
    "# Conference Board data summary\n",
    "if not conf_board_data.empty:\n",
    "    print(f\"   Conference Board Consumer Confidence: 1 indicator\")\n",
    "else:\n",
    "    print(f\"   Conference Board Consumer Confidence: Not available\")\n",
    "\n",
    "# Business sentiment data summary\n",
    "if not business_data.empty:\n",
    "    print(f\"   Business Sentiment Indicators: {business_data.shape[1]} indicators\")\n",
    "    print(f\"      - ISM PMI, NFIB Optimism, CEO Confidence, etc.\")\n",
    "else:\n",
    "    print(f\"   Business Sentiment Indicators: Not available\")\n",
    "\n",
    "print(f\"\\nData Storage:\")\n",
    "print(f\"   Raw data saved in: {DATA_DIR}/[source]/\")\n",
    "print(f\"   Integrated data saved in: {integrated_path}\")\n",
    "\n",
    "print(f\"\\nData collection completed successfully!\")\n",
    "print(f\"   The integrated dataset is ready for feature engineering and analysis.\")\n",
    "print(f\"   Next step: Run notebook 01_data_exploration.ipynb\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
