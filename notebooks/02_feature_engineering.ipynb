{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Economic Downturn Detector: Feature Engineering\n",
    "\n",
    "This notebook focuses on preparing the data for modeling by handling missing values, creating lag variables, and normalizing the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import notebook utilities\n",
    "from notebook_utils import (\n",
    "    # Setup functions\n",
    "    setup_notebook, load_data, display_data_info, save_figure,\n",
    "    \n",
    "    # Import from econ_downturn package\n",
    "    engineer_features, normalize_data, apply_pca\n",
    ")\n",
    "\n",
    "# Import other libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from IPython.display import display\n",
    "\n",
    "# Set up the notebook environment\n",
    "setup_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the Merged Dataset\n",
    "\n",
    "First, let's load the merged dataset created in the data exploration notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load all data using the utility function\n",
    "merged_data = load_data(use_cached=True)\n",
    "\n",
    "# Display information about the dataset\n",
    "display_data_info(merged_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering\n",
    "\n",
    "Let's perform feature engineering on the dataset to prepare it for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Engineer features using the package function\n",
    "data_with_features = engineer_features(merged_data)\n",
    "\n",
    "print(f\"Data shape after feature engineering: {data_with_features.shape}\")\n",
    "print(f\"Number of features: {data_with_features.shape[1]}\")\n",
    "\n",
    "# Display the first few rows of the engineered data\n",
    "display(data_with_features.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Normalize the Data\n",
    "\n",
    "Let's normalize the features to ensure they are on the same scale for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Normalize the data\n",
    "data_normalized, scaler = normalize_data(data_with_features)\n",
    "\n",
    "print(f\"Data shape after normalization: {data_normalized.shape}\")\n",
    "\n",
    "# Display the first few rows of the normalized data\n",
    "display(data_normalized.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Apply Principal Component Analysis (PCA)\n",
    "\n",
    "Let's apply PCA to reduce dimensionality and handle multicollinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Separate features and target\n",
    "X = data_normalized.drop(columns=['recession'])\n",
    "y = data_normalized['recession']\n",
    "\n",
    "# Apply PCA\n",
    "X_pca, pca, explained_variance = apply_pca(X, n_components=0.95)\n",
    "\n",
    "# Create a DataFrame with PCA components\n",
    "pca_cols = [f'PC{i+1}' for i in range(X_pca.shape[1])]\n",
    "X_pca_df = pd.DataFrame(X_pca, columns=pca_cols, index=X.index)\n",
    "\n",
    "# Add back the recession indicator\n",
    "X_pca_df['recession'] = y\n",
    "\n",
    "print(f\"Data shape after PCA: {X_pca_df.shape}\")\n",
    "print(f\"Number of PCA components: {X_pca.shape[1]}\")\n",
    "print(f\"Cumulative explained variance: {explained_variance:.4f}\")\n",
    "\n",
    "# Plot explained variance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(1, len(pca.explained_variance_ratio_) + 1), pca.explained_variance_ratio_)\n",
    "plt.plot(range(1, len(pca.explained_variance_ratio_) + 1), \n",
    "         np.cumsum(pca.explained_variance_ratio_), 'r-')\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.title('Explained Variance by Principal Components')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save the figure\n",
    "save_figure(plt.gcf(), \"pca_explained_variance.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Save the Processed Data\n",
    "\n",
    "Let's save the processed datasets for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Get output paths\n",
    "from econ_downturn import get_output_paths\n",
    "output_paths = get_output_paths()\n",
    "output_dir = output_paths['data_dir']\n",
    "\n",
    "# Save the dataset with features\n",
    "data_path = os.path.join(output_dir, 'data_with_features.csv')\n",
    "data_with_features.to_csv(data_path)\n",
    "print(f\"Saved dataset with features to {data_path}\")\n",
    "\n",
    "# Save the normalized dataset\n",
    "normalized_path = os.path.join(output_dir, 'data_normalized.csv')\n",
    "data_normalized.to_csv(normalized_path)\n",
    "print(f\"Saved normalized dataset to {normalized_path}\")\n",
    "\n",
    "# Save the PCA dataset\n",
    "pca_path = os.path.join(output_dir, 'data_pca.csv')\n",
    "X_pca_df.to_csv(pca_path)\n",
    "print(f\"Saved PCA dataset to {pca_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Next Steps\n",
    "\n",
    "Based on the feature engineering, the next steps would be:\n",
    "\n",
    "1. Apply Multiple Discriminant Analysis (MDA) to identify the most significant predictors of recessions\n",
    "2. Evaluate the model's performance in classifying recessionary and non-recessionary periods\n",
    "3. Interpret the results and identify the most important economic indicators for predicting recessions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
